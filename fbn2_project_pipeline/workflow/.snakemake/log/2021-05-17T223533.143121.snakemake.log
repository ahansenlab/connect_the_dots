Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=240
Job counts:
	count	jobs
	1	all
	22	get_trajectories_from_timeseries
	23

[Mon May 17 22:35:33 2021]
rule get_trajectories_from_timeseries:
    input: /mnt/md0/Hansen Lab Dropbox/DataStorage/Imaging/Fbn2/processed/2021_05_reprocessed/2020_12_09_Rad21F1M_fourhoursIAA_488nm_0p5_561nm_0p05_SC8_2X_30z_250nm_SC8_780V_365T_20s_movie3-01.czi
    output: results/Rad21_4_hr/2020_12_09_Rad21F1M_fourhoursIAA_488nm_0p5_561nm_0p05_SC8_2X_30z_250nm_SC8_780V_365T_20s_movie3-01.czi.tracks.csv, results/Rad21_4_hr/2020_12_09_Rad21F1M_fourhoursIAA_488nm_0p5_561nm_0p05_SC8_2X_30z_250nm_SC8_780V_365T_20s_movie3-01.czi.dot_volumes.pkl
    jobid: 158
    wildcards: group=Rad21_4_hr, sample=2020_12_09_Rad21F1M_fourhoursIAA_488nm_0p5_561nm_0p05_SC8_2X_30z_250nm_SC8_780V_365T_20s_movie3-01.czi
    resources: mem_gb=200

Terminating processes on user request, this might take some time.
Job failed, going on with independent jobs.
Complete log: /home/hbrandao/libs/data_analysis_Fbn2/snakemake/workflow/.snakemake/log/2021-05-17T223533.143121.snakemake.log
