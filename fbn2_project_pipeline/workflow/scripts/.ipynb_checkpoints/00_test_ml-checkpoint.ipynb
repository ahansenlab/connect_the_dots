{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required modules\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.keras import TqdmCallback\n",
    "import keras\n",
    "from connect_the_dots.filtering import create_mask_symmetric\n",
    "\n",
    "\n",
    "def data_to_keras_input(dot_volume_ch0, centroids_ch0, dot_volume_ch1, centroids_ch1,data_shape=(12,12,8)):\n",
    "    new_vol = np.zeros((data_shape[0],data_shape[1],data_shape[2],4))\n",
    "    z, x, y = centroids_ch0[0]\n",
    "    \n",
    "    for vi, (vol, loc) in enumerate([(dot_volume_ch0,centroids_ch0),(dot_volume_ch1,centroids_ch1)]):        \n",
    "        # prepare the raw voxel\n",
    "        z, x, y = loc[0]\n",
    "        raw_vol = vol\n",
    "        lenZ, lenX, lenY  = raw_vol.shape\n",
    "        vol = np.moveaxis(vol, 0, 2)\n",
    "        vol_min = np.min(vol)\n",
    "        vol_max = np.max(vol)\n",
    "        raw_vox = (vol-vol_min)/(vol_max-vol_min)*2 - 1\n",
    "        new_vol[:lenX, :lenY, :lenZ, vi] = raw_vox\n",
    "        # prepare the localization voxel\n",
    "        mask = create_mask_symmetric(raw_vol,x,y,z)\n",
    "        mask = np.moveaxis(mask, 0, 2)\n",
    "        new_vol[:lenX, :lenY, :lenZ, 2 + vi] = raw_vox*mask\n",
    "\n",
    "    return np.array([new_vol]), np.c_[centroids_ch0,centroids_ch1]/np.r_[data_shape,data_shape]\n",
    "\n",
    "# load models for the CNN classification\n",
    "ml_folder = 'ml_models/'\n",
    "replication_model = keras.models.load_model(os.path.join(ml_folder,'Replication_model_2021_04_14_hugo_classifications.h5'))\n",
    "good_bad_model = keras.models.load_model(os.path.join(ml_folder,'4D_model_2021_04_08_mixedInputClean_v2_doubleClassification.h5'))\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "S = pickle.load(open(snakemake.input.dot_volumes,'rb')) # load dot volume\n",
    "S_df = pd.read_csv(snakemake.input.traj) # load trajectory \n",
    "S_df['ML_class'] = ['Unclassified']*len(S_df) # new column for classification of Good/Bad dots\n",
    "S_df['ML_isReplicated'] = ['Unclassified']*len(S_df) # new column for classification of Replication or not\n",
    "\n",
    "\n",
    "# for each particle, use CNN to classify the dot\n",
    "for p in sorted(list(S.keys())): \n",
    "    total += 1\n",
    "    keep_frame = []\n",
    "    discard_frame = []\n",
    "    replicated_frame = []\n",
    "    unreplicated_frame = []        \n",
    "    no_dot = []\n",
    "\n",
    "    print(f'idx = {idx}, particle #{p} ')\n",
    "    print(f'Keys: ({S.keys()}) ')            \n",
    "\n",
    "    max_frame = max([max(list(sorted(S[p][c].keys()))) for c in list(sorted(S[p].keys()))])\n",
    "    min_frame = min([min(list(sorted(S[p][c].keys()))) for c in list(sorted(S[p].keys()))])\n",
    "    both_spots_localized = np.ones(max_frame+1, dtype=bool)\n",
    "    both_spots_localized[:min_frame] = False\n",
    "\n",
    "    channels = list(sorted(S[p].keys()))\n",
    "\n",
    "    for c in channels :\n",
    "        for frame in list(sorted(S[p][c].keys())):\n",
    "            if np.any(np.isnan(S[p][c][frame][1])):\n",
    "                both_spots_localized[frame] = False\n",
    "\n",
    "    # get frames that exist in both channels\n",
    "    frames_dict = {c:list(sorted(S[p][c].keys())) for c in channels} # get list of frames for each channel\n",
    "    consensus_frames = sorted(list(set(frames_dict[0]).intersection(set(frames_dict[1])))) \n",
    "\n",
    "    count = 0\n",
    "    for f, frame in enumerate(consensus_frames):\n",
    "        try:\n",
    "            dot_volume_ch0, centroids_ch0, centroids_ch0_true = S[p][0][frame]\n",
    "            dot_volume_ch1, centroids_ch1, centroids_ch1_true = S[p][1][frame]\n",
    "        except:\n",
    "            print(f\"Missing localization on frame {frame}\")\n",
    "            continue                                    \n",
    "\n",
    "        is_good = True\n",
    "        is_replicated = True\n",
    "        if (type(centroids_ch0)==tuple or type(centroids_ch1)==tuple)==False:\n",
    "            # prepare the dot volume for ML \n",
    "            try:\n",
    "                volume_data, loc_data =  data_to_keras_input(dot_volume_ch0, centroids_ch0, dot_volume_ch1, centroids_ch1)\n",
    "                is_good = good_bad_model.predict([volume_data, loc_data])[0][0]>0.5 # is good\n",
    "                is_replicated = replication_model.predict([volume_data, loc_data])[0][0]>0.5 # is replicated\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # keep track of replication\n",
    "        if is_replicated == True:\n",
    "            replicated_frame.append(frame) \n",
    "        else:\n",
    "            unreplicated_frame.append(frame) \n",
    "\n",
    "        # keep track of replication\n",
    "        if (is_good == True) and (both_spots_localized[frame]==True):\n",
    "            keep_frame.append(frame) \n",
    "        elif (is_good==False) and (both_spots_localized[frame]==True):\n",
    "            discard_frame.append(frame)\n",
    "        elif (both_spots_localized[frame]==False):\n",
    "            no_dot.append(frame)\n",
    "\n",
    "    S_df['ML_class'].mask((S_df.particle==p) & S_df.frame.isin(no_dot),'NoDot',inplace=True)\n",
    "    S_df['ML_class'].mask((S_df.particle==p) & S_df.frame.isin(discard_frame),'Bad',inplace=True)\n",
    "    S_df['ML_class'].mask((S_df.particle==p) & S_df.frame.isin(keep_frame),'Good',inplace=True)\n",
    "\n",
    "    S_df['ML_isReplicated'].mask((S_df.particle==p) & S_df.frame.isin(replicated_frame),'Replicated',inplace=True)\n",
    "    S_df['ML_isReplicated'].mask((S_df.particle==p) & S_df.frame.isin(unreplicated_frame),'Unreplicated',inplace=True)       \n",
    "S_df.to_csv(snakemake.output.traj_ml,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_df = pd.DataFrame()\n",
    "S_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def data_to_keras_input(dot_volume_ch0, centroids_ch0, dot_volume_ch1, centroids_ch1,data_shape=(12,12,8)):\n",
    "    new_vol = np.zeros((data_shape[0],data_shape[1],data_shape[2],4))\n",
    "    z, x, y = centroids_ch0[0]\n",
    "    \n",
    "    for vi, (vol, loc) in enumerate([(dot_volume_ch0,centroids_ch0),(dot_volume_ch1,centroids_ch1)]):        \n",
    "        # prepare the raw voxel\n",
    "        z, x, y = loc[0]\n",
    "        raw_vol = vol\n",
    "        lenZ, lenX, lenY  = raw_vol.shape\n",
    "        vol = np.moveaxis(vol, 0, 2)\n",
    "        vol_min = np.min(vol)\n",
    "        vol_max = np.max(vol)\n",
    "        raw_vox = (vol-vol_min)/(vol_max-vol_min)*2 - 1\n",
    "        new_vol[:lenX, :lenY, :lenZ, vi] = raw_vox\n",
    "        # prepare the localization voxel\n",
    "        mask = create_mask_symmetric(raw_vol,x,y,z)\n",
    "        mask = np.moveaxis(mask, 0, 2)\n",
    "        new_vol[:lenX, :lenY, :lenZ, 2 + vi] = raw_vox*mask\n",
    "\n",
    "    return np.array([new_vol]), np.c_[centroids_ch0,centroids_ch1]/np.r_[data_shape,data_shape]\n",
    "\n",
    "# load models for the CNN classification\n",
    "replication_model = keras.models.load_model(snakemake.input.ml_replication_model)\n",
    "good_bad_model = keras.models.load_model(snakemake.input.ml_good_bad_model)\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "S = pickle.load(open(snakemake.input.dot_volumes,'rb')) # load dot volume\n",
    "S_df = pd.read_csv(snakemake.input.traj) # load trajectory \n",
    "S_df['ML_class'] = ['Unclassified']*len(S_df) # new column for classification of Good/Bad dots\n",
    "S_df['ML_isReplicated'] = ['Unclassified']*len(S_df) # new column for classification of Replication or not\n",
    "\n",
    "\n",
    "# for each particle, use CNN to classify the dot\n",
    "for p in sorted(list(S.keys())): \n",
    "    keep_frame = []\n",
    "    discard_frame = []\n",
    "    replicated_frame = []\n",
    "    unreplicated_frame = []        \n",
    "    no_dot = []\n",
    "\n",
    "    max_frame = max([max(list(sorted(S[p][c].keys()))) for c in list(sorted(S[p].keys()))])\n",
    "    min_frame = min([min(list(sorted(S[p][c].keys()))) for c in list(sorted(S[p].keys()))])\n",
    "    both_spots_localized = np.ones(max_frame+1, dtype=bool)\n",
    "    both_spots_localized[:min_frame] = False\n",
    "\n",
    "    channels = list(sorted(S[p].keys()))\n",
    "\n",
    "    for c in channels :\n",
    "        for frame in list(sorted(S[p][c].keys())):\n",
    "            if np.any(np.isnan(S[p][c][frame][1])):\n",
    "                both_spots_localized[frame] = False\n",
    "\n",
    "    # get frames that exist in both channels\n",
    "    frames_dict = {c:list(sorted(S[p][c].keys())) for c in channels} # get list of frames for each channel\n",
    "    consensus_frames = sorted(list(set(frames_dict[0]).intersection(set(frames_dict[1])))) \n",
    "\n",
    "    count = 0\n",
    "    for f, frame in enumerate(consensus_frames):\n",
    "        \n",
    "        try:\n",
    "            dot_volume_ch0, centroids_ch0, centroids_ch0_true = S[p][0][frame]\n",
    "            dot_volume_ch1, centroids_ch1, centroids_ch1_true = S[p][1][frame]\n",
    "        except:\n",
    "            print(f\"Missing localization on frame {frame}\")\n",
    "            continue                                    \n",
    "\n",
    "        is_good = True\n",
    "        is_replicated = True\n",
    "        if (type(centroids_ch0)==tuple or type(centroids_ch1)==tuple)==False:\n",
    "            # prepare the dot volume for ML \n",
    "            try:\n",
    "                volume_data, loc_data =  data_to_keras_input(dot_volume_ch0, centroids_ch0, dot_volume_ch1, centroids_ch1)\n",
    "                is_good = good_bad_model.predict([volume_data, loc_data])[0][0]>0.5 # is good\n",
    "                is_replicated = replication_model.predict([volume_data, loc_data])[0][0]>0.5 # is replicated\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # keep track of replication\n",
    "        if is_replicated == True:\n",
    "            replicated_frame.append(frame) \n",
    "        else:\n",
    "            unreplicated_frame.append(frame) \n",
    "\n",
    "        # keep track of replication\n",
    "        if (is_good == True) and (both_spots_localized[frame]==True):\n",
    "            keep_frame.append(frame) \n",
    "        elif (is_good==False) and (both_spots_localized[frame]==True):\n",
    "            discard_frame.append(frame)\n",
    "        elif (both_spots_localized[frame]==False):\n",
    "            no_dot.append(frame)\n",
    "\n",
    "    S_df['ML_class'].mask((S_df.particle==p) & S_df.frame.isin(no_dot),'NoDot',inplace=True)\n",
    "    S_df['ML_class'].mask((S_df.particle==p) & S_df.frame.isin(discard_frame),'Bad',inplace=True)\n",
    "    S_df['ML_class'].mask((S_df.particle==p) & S_df.frame.isin(keep_frame),'Good',inplace=True)\n",
    "\n",
    "    S_df['ML_isReplicated'].mask((S_df.particle==p) & S_df.frame.isin(replicated_frame),'Replicated',inplace=True)\n",
    "    S_df['ML_isReplicated'].mask((S_df.particle==p) & S_df.frame.isin(unreplicated_frame),'Unreplicated',inplace=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from connect_the_dots.io import search_for\n",
    "from pathlib import Path\n",
    "def search_for(start_folder, name_includes=None, name_excludes=None):\n",
    "    filenames_list = []\n",
    "    filepath_list = []\n",
    "    for path in Path(start_folder).rglob('*.*'):\n",
    "\n",
    "        parent_folder = path.parent.name\n",
    "        if parent_folder in name_excludes:\n",
    "            continue   \n",
    "\n",
    "        if (all([name.lower() in path.name.lower() for name in name_includes])==False) or \\\n",
    "            any([name.lower() in path.name.lower() for name in name_excludes])==True:\n",
    "            continue\n",
    "            \n",
    "        filenames_list.append(path.name)\n",
    "        filepath_list.append(os.path.join(start_folder,path.parent.name))\n",
    "    return filenames_list, filepath_list\n",
    "existing_names, existing_folders = search_for('/mnt/md0/Hugo/',name_includes=['ML2.csv'],name_excludes=['sdfsadfasdf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fp, ff in zip(existing_folders,existing_names):\n",
    "#     os.remove(os.path.join(fp,ff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
